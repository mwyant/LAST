Summary (quick)
- App: FastAPI web UI + API for uploading audio, denoising, chunked transcription (NeMo ASR by default), diarization, and TTS.
- Key dirs (created on startup): /app/data/uploads, /app/data/out, /app/data/transcriptions
- Upload limit: 200 MiB (MAX_UPLOAD_BYTES)
- Chunk size default: 300s (CHUNK_SECONDS_DEFAULT)
- Default model: nvidia/parakeet-tdt-0.6b-v3 (loaded via NeMo)
- FFmpeg required. Demucs + torch.cuda optional for denoise GPU path.

Endpoints (list)
- GET / -> index (HTMLResponse) — serves templates/index.html (web UI)
- POST /upload -> upload_endpoint(file multipart/form-data) — upload audio, create Job
- POST /denoise -> denoise_endpoint(file multipart/form-data, lufs float=-16.0) — denoise, returns download link
- GET /denoise/download/{name} -> denoise_download(name) — download denoised WAV
- GET /denoise/job/{job_id} -> denoise_by_job(job_id) — returns OUT_DIR/{job_id}_denoised.wav if exists
- POST /transcribe -> transcribe_start(JSON payload {job_id, use_denoise?}) — enqueue transcription worker
- GET /events/{job_id} -> events(job_id) — SSE stream (status/progress/done/error)
- GET /status/{job_id} -> status(job_id) — job info JSON
- GET /download/{job_id} -> download(job_id) — download transcript text
- GET /metrics -> metrics() — returns METRICS JSON
- POST /admin/reload -> admin_reload() — reload currently configured model in background
- POST /admin/switch_model -> admin_switch_model(JSON {model_name}) — load a different model async
- GET /jobs -> list_jobs() — list all job states
- POST /synthesize -> synthesize_endpoint(JSON {text, model?}) — TTS synth; returns WAV streaming

Detailed endpoint docs, helper calls, side-effects, examples

GET /
- Purpose: returns the front-end web UI (templates/index.html).
- Example:
```
curl http://localhost:8000/
```
- Notes: index.html contains client code that speaks to the other endpoints.

POST /upload
- Handler: upload_endpoint(file: UploadFile)
- Request: multipart/form-data; form field name "file" with audio file.
- Accepts extensions: .wav, .mp3, .flac, .m4a, .ogg
- Size limit: MAX_UPLOAD_BYTES (200 MiB by default)
- Behavior:
  - Saves incoming file to UPLOAD_DIR as {job_id}{ext} (job_id generated by gen_job_id()).
  - Creates a Job object in JOBS with status "queued".
  - Emits initial job event.
  - METRICS["bytes_uploaded"] incremented.
- Response: JSON { "job_id": "<id>", "bytes": <n> }
- Example:
```
curl -F "file=@my_interview.wav" http://localhost:8000/upload
```
- Side-effects: file -> /app/data/uploads/{job_id}.ext ; JOBS updated.

POST /denoise
- Handler: denoise_endpoint(file: UploadFile, lufs: float = -16.0)
- Request: multipart/form-data; field "file". Optional form/query param lufs (float) - target LUFS.
- Behavior:
  - Saves upload to UPLOAD_DIR with a UID-based name.
  - Calls denoise_utils.denoise_chunk_auto(saved_in, OUT_DIR/{uid}_denoised.wav, lufs) in EXECUTOR to avoid blocking the event loop.
  - On success returns JSON with filename and a download path.
- Response: JSON { "filename": "<uid>_denoised.wav", "download": "/denoise/download/<uid>_denoised.wav" }
- Example:
```
curl -F "file=@noisy.wav" http://localhost:8000/denoise
```
- Side-effects: writes OUT_DIR/{uid}_denoised.wav

GET /denoise/download/{name}
- Purpose: download denoised WAV by filename.
- Response: FileResponse, media_type audio/wav
- Example:
```
curl -O http://localhost:8000/denoise/download/20250901-abc_denoi sed.wav
```

GET /denoise/job/{job_id}
- Purpose: convenience route that looks for OUT_DIR/{job_id}_denoised.wav and returns it if present.
- 404 if file missing.
- Example:
```
curl -I http://localhost:8000/denoise/job/<job_id>
curl -O http://localhost:8000/denoise/job/<job_id>
```

POST /transcribe
- Handler: transcribe_start(payload JSON)
- Request: JSON body. Required: {"job_id": "<id>"}; optional: {"use_denoise": true/false}
- Behavior:
  - Validates job exists in JOBS.
  - Submits transcription_worker(job.id, use_denoise) to EXECUTOR. (Note: see "probable bug" below.)
  - Sets job.status to "queued" and pushes status event.
- Response: JSON { "job_id": "<id>", "status": "queued" }
- Example:
```
curl -X POST -H "Content-Type: application/json" -d '{"job_id":"20231101010101-abc123","use_denoise":true}' http://localhost:8000/transcribe
```
- Side-effects: transcription_worker runs in background: denoise (via app.denoise_utils), chunking, transcribe chunks (MODEL.instance), diarize (app.diary or fallback), write transcript to TRANSCRIPT_DIR, emit SSE progress/done events.

Transcription worker details (important)
- transcription_worker(job_id, remove_input_after=True)
- Steps:
  1. Denoise/enhance via denoise_utils.denoise_chunk_auto -> OUT_DIR/{job.id}_denoised.wav (or fallback to raw input if denoise fails).
  2. Split denoised master into 48k segments via denoise_utils.split_into_chunks (SEG_CODEC pcm_s24le). If no split, fallback to single.
  3. For each segment:
     - Transcode to 16k mono WAV via transcode_to_wav (ffmpeg).
     - Check MODEL["ready"] and MODEL["instance"]; if not ready -> mark job failed.
     - Call run_transcribe_model(MODEL["instance"], chunk_path) and use transcript_to_human_readable to make timestamped lines.
     - Shift chunk timestamps by offset and combine.
  4. Diarize using app.diary.diarize / apply_diarization_to_lines if available, else fallback_diarize + apply_segments_to_lines.
  5. Write final transcript file with header to TRANSCRIPT_DIR/{gen_result_filename()}
  6. Update job.result_path, job.status, push done event.
- Files created: temporary workdir chunks, OUT_DIR denoised file, TRANSCRIPT_DIR result .txt
- Progress events: emits SSE events "progress", "done", "error" with job info.

GET /events/{job_id}
- Purpose: Server-Sent Events for job updates.
- Response: StreamingResponse text/event-stream, yields events created with push_job_event().
- Event types emitted (via push_job_event): status, progress, done, error
- To follow from shell:
```
curl -N http://localhost:8000/events/<job_id>
```
- Client in templates/index.html listens for those event names.

GET /status/{job_id}
- Response: job.to_dict() JSON with fields: id, status, created_at, updated_at, progress, message, input_path, transcode_path, result_path, error, model_name
- Example:
```
curl http://localhost:8000/status/<job_id>
```

GET /download/{job_id}
- Return the transcript text file stored at job.result_path (FileResponse text/plain)
- 404 if result_path not set or file missing
- Example:
```
curl -O http://localhost:8000/download/<job_id>
```

GET /metrics
- JSON dump of METRICS (jobs_created, jobs_completed, jobs_failed, bytes_uploaded)
- Example:
```
curl http://localhost:8000/metrics
```

POST /admin/reload
- Triggers load_model(MODEL["name"]) asynchronously in background.
- No auth — admin endpoints are open by default (tighten in production).
- Response: JSON {"status":"reloading", "model": "<current name>"}
- Example:
```
curl -X POST http://localhost:8000/admin/reload
```

POST /admin/switch_model
- Request: JSON { "model_name": "<huggingface/nemo model id>" }
- Action: load_model(model_name) scheduled in executor
- Response: JSON {"status":"switching", "model": "<model_name>"}
- Example:
```
curl -X POST -H "Content-Type: application/json" -d '{"model_name":"nvidia/parakeet-tdt-0.6b-v3"}' http://localhost:8000/admin/switch_model
```

GET /jobs
- Returns JSON mapping job_id -> job.to_dict()
- Example:
```
curl http://localhost:8000/jobs
```

POST /synthesize
- Request: JSON { "text": "<text>", "model": "<optional model name>" }
- Behavior:
  - Schedules a call to app.speech.synthesize_text(text, model) in EXECUTOR.
  - synthesize_text tries NeMo TTS first, then Coqui TTS fallback.
  - Returns StreamingResponse WAV (audio/wav).
- Requirements: nemo (nemo.collections.tts) or Coqui TTS installed. May require GPU for reasonable speed.
- Example:
```
curl -X POST -H "Content-Type: application/json" -d '{"text":"Hello from Izzy","model":null}' http://localhost:8000/synthesize --output izzy.wav
```

Extra: Stable-audio endpoints in app/speech.py
- app/speech.py defines an APIRouter with:
  - GET /stable-audio/ping
  - GET /stable-audio/generate?prompt=...&seconds=...&seed=...&steps=...&guidance_scale=...
- BUT main.py does not include router via app.include_router(), so these routes are not mounted by default.
- If you want them active, add in main.py:
  ```
  from app.speech import router as sa_router
  app.include_router(sa_router)
  ```
- Env vars used by that router:
  - SA_MODEL_ID, SA_SAMPLE_RATE, SA_STEPS, SA_GUIDANCE, SA_DEVICE, SA_DTYPE, HF_TOKEN/HUGGINGFACE_HUB_TOKEN
- Example (if router included):
```
curl "http://localhost:8000/stable-audio/generate?prompt=rain&seconds=8" --output sa.wav
```

Runtime / deployment notes (important)
- APP_ROOT is hard-coded to Path("/app"). On container images this is fine. If you run locally from repo root without adjusting, the server will create /app/* directories at root. If you want data under the repo, set APP_ROOT in code or change Path("/app") to Path(__file__).resolve().parents[1] or similar.
- FFmpeg is required (transcode_to_wav and denoise utilities call ffmpeg and ffprobe). main.py warns on startup if ffmpeg not found.
- Model load:
  - Default uses NeMo ASR: import nemo.collections.asr as nemo_asr and NemoModel.from_pretrained(MODEL_NAME). This is heavy (GPU-friendly) and can take time + memory.
  - Model loading is scheduled on startup in executor so server starts while model loads.
- Denoise:
  - Uses demucs (if demucs binary present and torch.cuda available) for GPU stem separation, else CPU fallback using noisereduce + pyloudnorm + ffmpeg filters.
- Diarization:
  - Uses app/diary.py (librosa + sklearn) if available; fallback_diarize exists in main.py in case imports fail.
- Threadpool size: EXECUTOR = ThreadPoolExecutor(max_workers=2) — transcription and heavy tasks will share two worker threads.
- Security: admin endpoints are unauthenticated (not for public use).

Small probable bug to be aware of
- transcription_worker signature: transcription_worker(job_id: str, remove_input_after: bool = True)
- transcribe_start passes: loop.run_in_executor(EXECUTOR, transcription_worker, job.id, use_denoise)
  - Here the second arg is use_denoise (a boolean), but transcription_worker expects remove_input_after — there is a mismatch. So the boolean you pass as use_denoise will be interpreted as remove_input_after in the worker (meaning the worker might delete input files if true). There is no code path in worker that honors a use_denoise flag currently. Likely intended to pass a use_denoise flag and have worker consume it; or worker param should be use_denoise. Consider changing transcription_worker signature to (job_id, use_denoise=False) and using that flag to select whether to run denoising step, or pass remove_input_after in transcribe_start intentionally if you want input removed.

Suggested fixes (brief)
- If you want use_denoise behavior, change transcription_worker signature and logic accordingly.
- If you want stable-audio endpoints active, app.include_router(app.speech.router) in main.py.
- Consider configurable APP_ROOT via env var so running on host doesn't create /app.

Quick curl examples (copy/paste)
- Upload:
```
curl -F "file=@my_audio.wav" http://localhost:8000/upload
```
- Start transcription (after upload returns job_id):
```
curl -X POST -H "Content-Type: application/json" -d '{"job_id":"<job_id>", "use_denoise": false}' http://localhost:8000/transcribe
```
- Follow SSE (watch events/progress):
```
curl -N http://localhost:8000/events/<job_id>
```
- Fetch status:
```
curl http://localhost:8000/status/<job_id>
```
- Download transcript:
```
curl -O http://localhost:8000/download/<job_id>
```
- Denoise upload-only:
```
curl -F "file=@noisy.wav" http://localhost:8000/denoise
```
- Synthesize (TTS):
```
curl -X POST -H "Content-Type: application/json" -d '{"text":"Hello, this is a test."}' http://localhost:8000/synthesize --output tts.wav
```
- Admin reload model:
```
curl -X POST http://localhost:8000/admin/reload
```
